{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sexual-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib qt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fundamental-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera(images, grid_size=(9, 6)):\n",
    "    \"\"\"\n",
    "    Calibrate camera parameters using images of \n",
    "    chesseboard\n",
    "\n",
    "    :param images list : list of image path\n",
    "    :param grid_size tuple: size of grid\n",
    "    :param image_size tuple: size of image\n",
    "    \"\"\"\n",
    "    if len(images) < 10:\n",
    "        print('Not enough images for clibration!')\n",
    "        return\n",
    "    gw, gh = grid_size\n",
    "    objp = np.zeros((gw*gh,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:gw, 0:gh].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    img_size = (0,0)\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_size = gray.shape\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (gw,gh), None)\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx, dist, img_size, 1, img_size)\n",
    "    return mtx, dist, newcameramtx, roi\n",
    "\n",
    "def undistort_image(img, mtx, dist, newcameramtx=None, roi=None):\n",
    "    \"\"\"\n",
    "    undistort image\n",
    "\n",
    "    :param img image: image to be undistort\n",
    "    :param mtx matrix: matrix for undisortion\n",
    "    :param dist matrix : dist coeffients\n",
    "    :param newcameramtx matrix: new camera matirx\n",
    "    :param roi tuple: roi of valid pixels  \n",
    "    \"\"\"\n",
    "    if (newcameramtx != None) and (roi != None):\n",
    "        x,y,w,h = roi\n",
    "        dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "    else:\n",
    "        dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liked-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imgs(im1, im2, titles=('IM1', 'IM2')):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(im1)\n",
    "    ax1.set_title(titles[0], fontsize=50)\n",
    "    ax2.imshow(im2)\n",
    "    ax2.set_title(titles[1], fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bulgarian-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    else:\n",
    "        return img\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    sobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    sobel = np.uint8(255 * sobel / np.max(sobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(sobel)\n",
    "    binary_output[(sobel >= thresh[0]) & (sobel <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude \n",
    "    sobel = np.sqrt(sobel_x * sobel_x + sobel_y * sobel_y)\n",
    "    \n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    sobel = np.uint8(255 * sobel / np.max(sobel))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(sobel)\n",
    "    binary_output[(sobel >= mag_thresh[0]) & (sobel <= mag_thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    sobel_x = np.abs(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    sobel_y = np.abs(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    grad_angle = np.arctan2(sobel_y, sobel_x);\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(grad_angle)\n",
    "    binary_output[(grad_angle >= thresh[0]) & (grad_angle <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "                   \n",
    "                   \n",
    "def hls_select(img, thresh=(0, 255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    img_hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    binary_output = np.zeros_like(img_hls[:,:,-1])\n",
    "    #binary_output = img_hls[:,:,-1]\n",
    "    binary_output[(img_hls[:,:,-1] >= thresh[0]) & (img_hls[:,:,-1] <= thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary_output\n",
    "\n",
    "def combined_filter(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sx_idx = (scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])\n",
    "    sxbinary[sx_idx] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_idx = (s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])\n",
    "    s_binary[s_idx] = 1\n",
    "    \n",
    "    s_binary_new = np.zeros_like(s_channel)\n",
    "    #s_binary_new[s_idx | sx_idx] = 255\n",
    "    s_binary_new[s_idx | sx_idx ] = 255\n",
    "    \n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    return s_binary_new, color_binary\n",
    "    #return s_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-aviation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aerial-principle",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_ims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8b174be5ae5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundistort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwarped_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarpPerspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperspective_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfiltered_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_im_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfiltered_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msobel_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_ims' is not defined"
     ]
    }
   ],
   "source": [
    "test_im = cv2.imread(test_ims[1])\n",
    "dst = cv2.undistort(test_im, mtx, dist, None, mtx)\n",
    "warped_im = cv2.warpPerspective(dst, perspective_matrix, (dst.shape[1], dst.shape[0]), cv2.INTER_LINEAR)\n",
    "filtered_im, filtered_im_color = combined_filter(test_im)\n",
    "filtered_im = dir_threshold(test_im, sobel_kernel=3, thresh=(np.pi/(2*3), np.pi/(2*3)*2))\n",
    "plot_imgs(test_im[:,:,::-1], filtered_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrative-gentleman",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_perspective_transform(size, src_vertices, offset=(300, 0)):\n",
    "    offset_x, offset_y = offset\n",
    "    w, h = size\n",
    "    dst_vertices = np.array([[offset_x, h], [offset_x, offset_y], [w-offset_x, offset_y], [w-offset_x, h]], dtype=np.float32)\n",
    "    m = cv2.getPerspectiveTransform(src_vertices, dst_vertices)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nuclear-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped, nwindows=9, xmargin=100, minpix=20):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - xmargin\n",
    "        win_xleft_high = leftx_current + xmargin  # Update this\n",
    "        win_xright_low = rightx_current - xmargin  # Update this\n",
    "        win_xright_high = rightx_current + xmargin  # Update this\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        y_idx = (nonzeroy >= win_y_low) & (nonzeroy < win_y_high)\n",
    "        good_left_inds = ((nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high) & y_idx).nonzero()[0]\n",
    "        good_right_inds = ((nonzerox >= win_xright_low) & (nonzerox < win_xright_high) & y_idx).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = nonzerox[good_left_inds].mean().astype(int)\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = nonzerox[good_right_inds].mean().astype(int)\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eligible-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial(left, right):\n",
    "    leftx, lefty = left\n",
    "    rightx, righty = right\n",
    "    left_fit = np.polyfit(lefty, leftx,  2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    return left_fit, right_fit\n",
    "    \n",
    "def __fit_polynomial(left, right, binary_warped):\n",
    "    leftx, lefty = left\n",
    "    rightx, righty = right\n",
    "    left_fit = np.polyfit(lefty, leftx,  2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "attractive-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_around_poly(binary_warped, left_fit, right_fit, margin=100):\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    nonzero_x_curve_left = left_fit[0] * nonzeroy**2 + left_fit[1] * nonzeroy + left_fit[2]\n",
    "    nonzero_x_curve_right = right_fit[0] * nonzeroy**2 + right_fit[1] * nonzeroy + right_fit[2]\n",
    "    left_lane_inds = (nonzerox >= nonzero_x_curve_left - margin) & (nonzerox < nonzero_x_curve_left + margin)\n",
    "    right_lane_inds = (nonzerox >= nonzero_x_curve_right - margin) & (nonzerox < nonzero_x_curve_right + margin)\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    return (leftx, lefty), (rightx, righty)\n",
    "    \n",
    "def visualize_poly(binary_warped, left_pixs, right_pixs, left_fit, right_fit, margin=100):\n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    leftx, lefty = left_pixs\n",
    "    rightx, righty = right_pixs\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "    \n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin,  ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sweet-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coef_pix2m(coef, xm_per_pix, ym_per_pix):\n",
    "    a = coef[0] * xm_per_pix / (ym_per_pix**2)\n",
    "    b = coef[0] * xm_per_pix / ym_per_pix\n",
    "    return np.array([a, b, coef[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "linear-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature(left_fit, right_fit, y_eval):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    left_curverad = ((1 + (2*left_fit[0] * y_eval + left_fit[1])**2)**(3/2))/abs(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0] * y_eval + right_fit[1])**2)**(3/2))/abs(2*right_fit[0])\n",
    "    \n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-miller",
   "metadata": {},
   "source": [
    "### 1. Calibrate camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "heated-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_path = 'camera_cal/*.jpg'\n",
    "mtx, dist, newcameramtx, roi = calibrate_camera(glob.glob(cali_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "southwest-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread(glob.glob(cali_path)[1])\n",
    "undis_img = undistort_image(test_img, mtx, dist)\n",
    "plot_imgs(test_img, undis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wrong-packet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.63723306e-04,  0.00000000e+00, -5.76201786e-01],\n",
       "       [ 0.00000000e+00,  8.67436472e-04, -3.34938546e-01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "incorporated-proceeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24688507, -0.02373154, -0.00109831,  0.00035107, -0.00259869]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-offering",
   "metadata": {},
   "source": [
    "### 2. Filter image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "national-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ims = glob.glob('test_images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "convinced-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_im = undistort_image(cv2.imread(test_ims[1])[:,:,::-1], mtx, dist)\n",
    "filtered_im, filtered_im_color = combined_filter(test_im)\n",
    "cv2.imwrite('writeup_ims/test_im.png', test_im[:,:,::-1])\n",
    "plot_imgs(test_im, filtered_im)\n",
    "#cv2.imwrite('writeup_ims/filtered.png', filtered_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-dominant",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Perspective Transfomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "naked-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#points_x = np.array([206, 588, 697, 1113])\n",
    "#points_y = np.array([720, 455, 455, 720])\n",
    "#points_x = np.array([206, 598, 687, 1113])\n",
    "#points_y = np.array([720, 455, 455, 720])\n",
    "y_top = 0.62\n",
    "x_low = 0.12\n",
    "x_top_ctr = 0.034\n",
    "#points_x = np.array([x_low, 0.5-x_top_ctr, 0.5+x_top_ctr, 1-x_low])*1280 \n",
    "#points_y = np.array([1, y_top, y_top, 1])*720\n",
    "points_x = np.array([0.1609375 , 0.4671875 , 0.53671875, 0.86953125]) * 1280\n",
    "points_y = np.array([1, 0.63194444, 0.63194444, 1]) * 720\n",
    "vertices = np.vstack((points_x, points_y)).transpose().astype(np.float32)\n",
    "perspective_matrix = get_perspective_transform((1280, 720), vertices)\n",
    "# draw lines \n",
    "#fim = filtered_im.copy()\n",
    "fim = test_im.copy()\n",
    "for i in range(4):\n",
    "    p1 = vertices[i].astype(int)\n",
    "    p2 = vertices[(i+1)%4].astype(int)\n",
    "    cv2.line(fim, tuple(p1), tuple(p2), (255, 0,0), 2)\n",
    "warped_im = cv2.warpPerspective(test_im.copy(), perspective_matrix, (filtered_im.shape[1], filtered_im.shape[0]), cv2.INTER_LINEAR)\n",
    "%matplotlib qt\n",
    "#%matplotlib inline\n",
    "plot_imgs(fim, warped_im, titles=('Undistorted', 'Wraped'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-pound",
   "metadata": {},
   "source": [
    "### 4. Find Line Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "brown-penguin",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /tmp/opencv-20210228-9361-r4z33j/opencv-4.5.1/modules/core/src/array.cpp:3229: error: (-215:Assertion failed) cn <= 4 in function 'scalarToRawData'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-0757e6b6ef7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# inti with sliding windows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mleftx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlefty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrighty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_lane_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mleft_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_polynomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleftx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlefty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrightx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrighty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mleft_pixs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_pixs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_around_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnew_left_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_right_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_polynomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_pixs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_pixs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7f757074aabb>\u001b[0m in \u001b[0;36mfind_lane_pixels\u001b[0;34m(binary_warped, nwindows, xmargin, minpix)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Draw the windows on the visualization image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n\u001b[0m\u001b[1;32m     39\u001b[0m         (win_xleft_high,win_y_high),(0,255,0), 2) \n\u001b[1;32m     40\u001b[0m         cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/opencv-20210228-9361-r4z33j/opencv-4.5.1/modules/core/src/array.cpp:3229: error: (-215:Assertion failed) cn <= 4 in function 'scalarToRawData'\n"
     ]
    }
   ],
   "source": [
    "# inti with sliding windows\n",
    "leftx, lefty, rightx, righty, out_im = find_lane_pixels(warped_im)\n",
    "left_fit, right_fit = fit_polynomial((leftx, lefty), (rightx, righty))\n",
    "left_pixs, right_pixs = search_around_poly(warped_im, left_fit, right_fit, margin=80)\n",
    "new_left_fit, new_right_fit = fit_polynomial(left_pixs, right_pixs)\n",
    "vis_im = visualize_poly(warped_im, left_pixs, right_pixs, new_left_fit, new_right_fit, margin=80)\n",
    "plot_imgs(warped_im, vis_im)\n",
    "#def convert_coef_pix2m(coef, xm_per_pix, ym_per_pix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cooperative-chase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54172.347362387016 27142.18482356291\n"
     ]
    }
   ],
   "source": [
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "# calculate real curvature\n",
    "left_fit_world = convert_coef_pix2m(new_left_fit, xm_per_pix, ym_per_pix)\n",
    "right_fit_world = convert_coef_pix2m(new_right_fit, xm_per_pix, ym_per_pix)\n",
    "#y_eval_world = (warped_im.shape[0]-1) * ym_per_pix\n",
    "y_eval_world = 2 * ym_per_pix\n",
    "left_curverad, right_curverad = measure_curvature(left_fit_world, right_fit_world, y_eval_world )\n",
    "print(left_curverad, right_curverad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "elect-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791.6368837142412"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "blessed-victor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21758.030643239945"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init with sliding boxes\n",
    "# then search the pixels based on last fit polynomial \n",
    "# measure the curvature\n",
    "# if the curvature change to much, search again with sliding window\n",
    "# tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-qatar",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Fit polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-reform",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Calculate Curvature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-constraint",
   "metadata": {},
   "source": [
    "\n",
    "### 7. Convert back to original Image\n",
    "### 8. transform image coor. to world coor. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "funky-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(img):\n",
    "    filtered_im, filtered_im_color = combined_filter(img)\n",
    "    warped_im = cv2.warpPerspective(filtered_im, perspective_matrix, (filtered_im.shape[1], filtered_im.shape[0]), cv2.INTER_LINEAR)\n",
    "    leftx, lefty, rightx, righty, out_im = find_lane_pixels(warped_im)\n",
    "    left_fit, right_fit = fit_polynomial((leftx, lefty), (rightx, righty))\n",
    "    left_pixs, right_pixs = search_around_poly(warped_im, left_fit, right_fit, margin=80)\n",
    "    new_left_fit, new_right_fit = fit_polynomial(left_pixs, right_pixs)\n",
    "    vis_im = visualize_poly(warped_im, left_pixs, right_pixs, new_left_fit, new_right_fit, margin=80)\n",
    "    left_fit_world = convert_coef_pix2m(new_left_fit, xm_per_pix, ym_per_pix)\n",
    "    right_fit_world = convert_coef_pix2m(new_right_fit, xm_per_pix, ym_per_pix)\n",
    "    y_eval_world = (warped_im.shape[0]-1) * ym_per_pix\n",
    "    y_eval_world = 2 * ym_per_pix\n",
    "    left_curverad, right_curverad = measure_curvature(left_fit_world, right_fit_world, y_eval_world )\n",
    "    #print(left_curverad, right_curverad)\n",
    "    return vis_im\n",
    "    #return warped_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "british-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "\n",
    "class Line:\n",
    "    def __init__(self, x, y, line_coef=None, xm_per_pix= 3.7/700, ym_per_pix= 30/720, poly_order=2):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.ym_per_pix = ym_per_pix\n",
    "        self.xm_per_pix = xm_per_pix\n",
    "        self.poly_order = poly_order\n",
    "        self._coef = line_coef\n",
    "        self._coef_world = None\n",
    "        self._curverad_world = None\n",
    "        self._x_base = None\n",
    "        self.y_max = self.y.max()\n",
    "    @property \n",
    "    def xy(self):\n",
    "        return (self.x, self.y)\n",
    "        \n",
    "    @property\n",
    "    def x_base(self):\n",
    "        if self._x_base is None:\n",
    "            self._x_base = self._get_x(self.y_max)\n",
    "        return self._x_base\n",
    "    @property\n",
    "    def coef(self):\n",
    "        if self._coef is None:\n",
    "            self._coef = np.polyfit(self.y, self.x,  self.poly_order)\n",
    "        return self._coef\n",
    "    \n",
    "    @property\n",
    "    def coef_world(self):\n",
    "        if self._coef_world is None:\n",
    "            self._coef_world = self._convert_coef_pix2m(self.coef, self.xm_per_pix, self.ym_per_pix)\n",
    "        return self._coef_world\n",
    "    @property\n",
    "    def curverad(self):\n",
    "        if self._curverad_world is None:\n",
    "            y_eval = self.y_max * self.ym_per_pix\n",
    "            self._curverad_world = ((1 + (2*self.coef_world[0] * y_eval + self.coef_world[1])**2)**(3/2))/abs(2*self.coef_world[0])\n",
    "        return self._curverad_world\n",
    "    \n",
    "    def _get_x(self, y):\n",
    "        return self.coef[0] * y**2 + self.coef[1] * y + self.coef[2]\n",
    "    \n",
    "    def _convert_coef_pix2m(self, coef, xm_per_pix, ym_per_pix):\n",
    "        a = coef[0] * xm_per_pix / (ym_per_pix**2)\n",
    "        b = coef[0] * xm_per_pix / ym_per_pix\n",
    "        return np.array([a, b, coef[2]])\n",
    "        \n",
    "        \n",
    "line_pair = namedtuple('Line_pair', ['left', 'right'])\n",
    "\n",
    "class Lane_finder:\n",
    "    \n",
    "    def __init__(self, perspective_mtx=None, camera_mtx=None, dist=None, buffer_size=3):\n",
    "        self.camera_mtx = camera_mtx\n",
    "        self.dist = dist\n",
    "        self.line_buffer = deque(maxlen=buffer_size)\n",
    "        self.init = False\n",
    "        self.curverad_diff_thresh = 500\n",
    "        self.x_base_diff_thresh = 500\n",
    "        self.min_curverad = 500\n",
    "        points_x = np.array([206, 588, 697, 1113])\n",
    "        points_y = np.array([720, 455, 455, 720])\n",
    "        self.src_vertices = np.vstack((points_x, points_y)).transpose().astype(np.float32)\n",
    "        self.perspective_mtx = perspective_mtx\n",
    "        self._inv_perspective_mtx = None\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def inv_perspective_mtx(self):\n",
    "        if self._inv_perspective_mtx is None:\n",
    "            self._inv_perspective_mtx = np.linalg.inv(self.perspective_mtx)\n",
    "        return self._inv_perspective_mtx\n",
    "        \n",
    "    @property\n",
    "    def last_line_pair(self):\n",
    "        if len(self.line_buffer) == 0:\n",
    "            return None\n",
    "        return self.line_buffer[-1]\n",
    "    \n",
    "    def get_perspective_transform(self, size, src_vertices, offset=(300, 0)):\n",
    "        offset_x, offset_y = offset\n",
    "        w, h = size\n",
    "        dst_vertices = np.array([[offset_x, h], [offset_x, offset_y], [w-offset_x, offset_y], [w-offset_x, h]], dtype=np.float32)\n",
    "        return cv2.getPerspectiveTransform(src_vertices, dst_vertices)\n",
    "    \n",
    "    def check_valid(self, line_pair):\n",
    "        if len(self.line_buffer) == 0:\n",
    "            return True\n",
    "        # check mininal of radius of curve\n",
    "        if line_pair.left.curverad < self.min_curverad or line_pair.right.curverad < self.min_curverad:\n",
    "            #print('curverad too small')\n",
    "            return False\n",
    "        # check diff of radius of curve\n",
    "        left_curverad_invalid =  abs(line_pair.left.curverad - self.last_line_pair.left.curverad) > self.curverad_diff_thresh\n",
    "        right_curverad_invalid =  abs(line_pair.right.curverad - self.last_line_pair.right.curverad) > self.curverad_diff_thresh\n",
    "        #print('current_left curverad: {}, last left curverad: {}'.format(line_pair.left.curverad, self.last_line_pair.left.curverad))\n",
    "        #print('current right curverad: {}, last right curverad: {}'.format(line_pair.right.curverad, self.last_line_pair.right.curverad))\n",
    "        if left_curverad_invalid or right_curverad_invalid:\n",
    "            #print('curverad diff too big')\n",
    "            return False\n",
    "        \n",
    "        #print('left x_base')\n",
    "        #print(abs(self.last_line_pair.left.x_base - line_pair.left.x_base))\n",
    "        #print('right x_base')\n",
    "        #print(abs(self.last_line_pair.right.x_base - line_pair.right.x_base))\n",
    "        # check x base\n",
    "        if abs(self.last_line_pair.left.x_base - line_pair.left.x_base) > self.x_base_diff_thresh \\\n",
    "            or abs(self.last_line_pair.right.x_base - line_pair.right.x_base) > self.x_base_diff_thresh:\n",
    "            #print('x_base diff too big')\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def get_avg_line_pair(self, n=0):\n",
    "        n_l = len(self.line_buffer)\n",
    "        if n == 0 or n > n_l: \n",
    "            n = n_l\n",
    "        left_coefs = []\n",
    "        right_coefs = []\n",
    "        for i in range(n_l-1, n_l-1-n, -1):\n",
    "            left_coefs.append(self.line_buffer[i].left.coef)\n",
    "            right_coefs.append(self.line_buffer[i].right.coef)\n",
    "        mean_left_coef = np.array(left_coefs).mean(axis=0)\n",
    "        mean_right_coef = np.array(right_coefs).mean(axis=0)\n",
    "        # use last pixs for average line for efficiency\n",
    "        left_line = Line(x=self.last_line_pair.left.x, y=self.last_line_pair.left.y, line_coef=mean_left_coef)\n",
    "        right_line = Line(x=self.last_line_pair.right.x, y=self.last_line_pair.right.y, line_coef=mean_right_coef)\n",
    "        return (left_line, right_line) \n",
    "            \n",
    "            \n",
    "    def process(self, img, vis='top'):\n",
    "        undistorted_img = cv2.undistort(img, self.camera_mtx, self.dist, None, self.camera_mtx)\n",
    "        filtered_im = self.filter_im(undistorted_img)\n",
    "        if self.perspective_mtx is None:\n",
    "            self.perspective_mtx = get_perspective_transform(\n",
    "                (undistorted_img.shape[1], undistorted_img.shape[0]),\n",
    "                 self.src_vertices)\n",
    "        warped_im = cv2.warpPerspective(filtered_im, \n",
    "                                        self.perspective_mtx, \n",
    "                                        (filtered_im.shape[1], filtered_im.shape[0]), \n",
    "                                        cv2.INTER_LINEAR)\n",
    "        if not self.init:\n",
    "            left_pixs, right_pixs, xbase = self.find_pixels_window(warped_im)\n",
    "            left_line = Line(left_pixs[0], left_pixs[1])\n",
    "            right_line = Line(right_pixs[0], right_pixs[1])\n",
    "            self.line_buffer.append(line_pair(left_line, right_line))\n",
    "            self.init = True\n",
    "        else:\n",
    "            left_pixs, right_pixs = self.search_around_poly(warped_im, \n",
    "                                                       self.last_line_pair.left.coef, \n",
    "                                                       self.last_line_pair.right.coef, \n",
    "                                                       margin=100)\n",
    "            left_line = Line(left_pixs[0], left_pixs[1])\n",
    "            right_line = Line(right_pixs[0], right_pixs[1])\n",
    "            if self.check_valid(line_pair(left_line, right_line)):\n",
    "                self.line_buffer.append(line_pair(left_line, right_line))\n",
    "            else: \n",
    "                self.init = False\n",
    "        if vis == 'top':\n",
    "            avg_line_left, avg_line_right = self.get_avg_line_pair()\n",
    "            #return self.vis_poly(warped_im, avg_line_left, avg_line_right)\n",
    "            return self.vis_poly(warped_im, self.last_line_pair.left, self.last_line_pair.right)\n",
    "        elif vis == 'camera':\n",
    "            avg_line_left, avg_line_right = self.get_avg_line_pair()\n",
    "            return self.vis_camera(undistorted_img, warped_im, avg_line_left, avg_line_right)\n",
    "        else:\n",
    "            return warped_im\n",
    "        \n",
    "    def filter_im(self, img, s_thresh=(130, 255), sx_thresh=(50, 130)):\n",
    "        # Convert to HLS color space and separate the V channel\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        l_channel = hls[:,:,1]\n",
    "        s_channel = hls[:,:,2]\n",
    "        # Sobel x\n",
    "        sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "        abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "        scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "        # Threshold x gradient\n",
    "        binary = np.zeros_like(scaled_sobel)\n",
    "        sx_idx = (scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])\n",
    "        binary[sx_idx] = 1\n",
    "\n",
    "        # Threshold color channel\n",
    "        s_idx = (s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])\n",
    "        binary[s_idx] = 1\n",
    "        return binary\n",
    "    \n",
    "    def vis_poly(self, binary_warped, left_line, right_line, margin=100):\n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        window_img = np.zeros_like(out_img)\n",
    "        # Color in left and right line pixels\n",
    "        leftx, lefty = left_line.xy\n",
    "        rightx, righty = right_line.xy\n",
    "        out_img[lefty, leftx] = [255, 0, 0]\n",
    "        out_img[righty, rightx] = [0, 0, 255]\n",
    "        left_fit = left_line.coef\n",
    "        right_fit = right_line.coef\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin,  ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        return result\n",
    "    \n",
    "    def vis_camera(self, original_img, warped_img, left_line, right_line):\n",
    "       # Create an image to draw the lines on\n",
    "        warp_zero = np.zeros_like(warped_img).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        ploty = np.linspace(0, warped_img.shape[0]-1, warped_img.shape[0])\n",
    "        left_fit = left_line.coef\n",
    "        right_fit = right_line.coef\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = cv2.warpPerspective(color_warp, self.inv_perspective_mtx, (original_img.shape[1], original_img.shape[0])) \n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(original_img, 1, newwarp, 0.3, 0)\n",
    "        return result\n",
    "        \n",
    "    def find_pixels_window(self, binary_warped, x_base=None, nwindows=9, xmargin=100, minpix=20):\n",
    "        if x_base is None:\n",
    "            histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "            midpoint = int(histogram.shape[0]//2)\n",
    "            leftx_base = np.argmax(histogram[:midpoint])\n",
    "            rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "        else:\n",
    "            leftx_base, rightx_base = x_base\n",
    "        window_height = int(binary_warped.shape[0]//nwindows)\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "            win_y_high = binary_warped.shape[0] - window*window_height\n",
    "            ### TO-DO: Find the four below boundaries of the window ###\n",
    "            win_xleft_low = leftx_current - xmargin\n",
    "            win_xleft_high = leftx_current + xmargin  # Update this\n",
    "            win_xright_low = rightx_current - xmargin  # Update this\n",
    "            win_xright_high = rightx_current + xmargin  # Update this\n",
    "\n",
    "            y_idx = (nonzeroy >= win_y_low) & (nonzeroy < win_y_high)\n",
    "            good_left_inds = ((nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high) & y_idx).nonzero()[0]\n",
    "            good_right_inds = ((nonzerox >= win_xright_low) & (nonzerox < win_xright_high) & y_idx).nonzero()[0]\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = nonzerox[good_left_inds].mean().astype(int)\n",
    "            if len(good_right_inds) > minpix:\n",
    "                rightx_current = nonzerox[good_right_inds].mean().astype(int)\n",
    "\n",
    "        # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "        return (leftx, lefty), (rightx, righty), (leftx_base, rightx_base)\n",
    "    \n",
    "    def search_around_poly(self, binary_warped, left_fit, right_fit, margin=100):\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        nonzero_x_curve_left = left_fit[0] * nonzeroy**2 + left_fit[1] * nonzeroy + left_fit[2]\n",
    "        nonzero_x_curve_right = right_fit[0] * nonzeroy**2 + right_fit[1] * nonzeroy + right_fit[2]\n",
    "        left_lane_inds = (nonzerox >= nonzero_x_curve_left - margin) & (nonzerox < nonzero_x_curve_left + margin)\n",
    "        right_lane_inds = (nonzerox >= nonzero_x_curve_right - margin) & (nonzerox < nonzero_x_curve_right + margin)\n",
    "\n",
    "        # Again, extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "        return (leftx, lefty), (rightx, righty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "exterior-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = Lane_finder(camera_mtx=mtx, dist=dist, buffer_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "liable-appearance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left x_base\n",
      "0.38160767302093745\n",
      "right x_base\n",
      "5.152570548975291\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "project_ims = glob.glob('project_images/out*.png')\n",
    "\n",
    "p = 'project_images/out{}.png'\n",
    "for i in range(580, 628):\n",
    "    test_im = cv2.imread(p.format(i))[:,:,::-1]\n",
    "    result = finder.process(test_im, 'camera')\n",
    "    cv2.imshow('img', result)\n",
    "    cv2.waitKey(100)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "meaningful-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finder1 = Lane_finder(perspective_mtx=perspective_matrix, camera_mtx=mtx, dist=dist, buffer_size=5)\n",
    "test_im = cv2.imread(p.format(585))[:,:,::-1]\n",
    "result = finder1.process(test_im, 'top')\n",
    "plot_imgs(test_im[:,:,::-1], result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-analyst",
   "metadata": {},
   "source": [
    "#### points for perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "accurate-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test video\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "royal-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video = 'project_video_out.mp4'\n",
    "\n",
    "#output_video = 'challenge_video_out.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"./project_video.mp4\")\n",
    "#clip1 = VideoFileClip(\"./challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(lambda im: finder.process(im, vis='camera')) #NOTE: this function expects color images!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "trying-privilege",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 3/1260 [00:00<01:04, 19.51it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video project_video_out.mp4.\n",
      "Moviepy - Writing video project_video_out.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready project_video_out.mp4\n"
     ]
    }
   ],
   "source": [
    "#white_clip.ipython_display(width=900, audio=False)\n",
    "white_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "noticed-summary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video_out.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-economy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
